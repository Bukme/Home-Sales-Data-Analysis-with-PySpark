# Home_Sales

### Introduction
This repository contains solutions to a data analysis challenge using PySpark, an Apache Spark Python API, and Parquet file format. The challenge involves performing various analytical tasks on a dataset of home sales.

### Files
**Home_Sales_starter_code_colab_d.ipynb**: This Jupyter Notebook contains the Python code to perform data analysis tasks using PySpark. Note that this notebook was originally created in Google Colab and may require uploading to Google Colab for execution.


### Usage
To run the data analysis tasks:
1. Download the `Home_Sales_starter_code_colab_d.ipynb` notebook file from this repository.
2. Upload the notebook file to Google Colab.
3. Ensure you have the required libraries and dependencies installed (e.g., PySpark).
4. Follow the instructions in the notebook and execute the code cells to perform the desired analysis tasks.

### References
- Mrjob v0.7.4 documentation. mrjob. (n.d.). [https://mrjob.readthedocs.io/en/latest/](https://mrjob.readthedocs.io/en/latest/)
- PySpark overview. PySpark Overview - PySpark master documentation. (n.d.). [https://spark.apache.org/docs/latest/api/python/](https://spark.apache.org/docs/latest/api/python/)

### Acknowledgments
Other resourceful ideas gotten from Class, Tutors, TAs, and other students.

---

This README provides a brief overview of the repository, its contents, how to use it, and references to resources used in solving the data analysis challenge. If you have any further questions or need additional assistance, feel free to reach out.
